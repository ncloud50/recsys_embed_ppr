{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.exception import NetworkXError\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "\n",
    "from dataloader import AmazonDataset\n",
    "import models\n",
    "from models import DistMulti, TransE\n",
    "from training import TrainIterater\n",
    "from evaluate import Evaluater\n",
    "\n",
    "import optuna\n",
    "import time \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'TransE'\n",
    "dataset = AmazonDataset('./data', model_name='TransE')\n",
    "edges = [[r[0], r[1]] for r in dataset.triplet_df.values]\n",
    "\n",
    "# ハイパラ\n",
    "best_params = pickle.load(open('./best_param.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_dim': 48.0,\n",
       " 'batch_size': 384,\n",
       " 'lr': 0.0007965458269452495,\n",
       " 'weight_decay': 1.0276080015781148e-06,\n",
       " 'warmup': 350,\n",
       " 'lr_decay_every': 2,\n",
       " 'lr_decay_rate': 0.6348448884535313}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KG embedする\n",
    "\n",
    "bestなハイパラパラメータを読み込んでepoch回す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_embed(params):\n",
    "    \n",
    "    # ハイパラ読み込み\n",
    "    embedding_dim = best_params['embedding_dim']\n",
    "    batch_size = best_params['batch_size']\n",
    "    lr = best_params['lr']\n",
    "    weight_decay = best_params['weight_decay']\n",
    "    warmup = best_params['warmup']\n",
    "    lr_decay_every = best_params['lr_decay_every']\n",
    "    lr_decay_rate = best_params['lr_decay_rate']\n",
    "    \n",
    "    relation_size = len(set(list(dataset.triplet_df['relation'].values)))\n",
    "    entity_size = len(dataset.entity_list)\n",
    "    model = TransE(int(embedding_dim), relation_size, entity_size).to(device)\n",
    "    iterater = TrainIterater(batch_size=int(batch_size), model_name=model_name)\n",
    "    score =iterater.iterate_epoch(model, lr=lr, epoch=5000, weight_decay=weight_decay, warmup=warmup,\n",
    "                           lr_decay_rate=lr_decay_rate, lr_decay_every=lr_decay_every, eval_every=1e+5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習済みembedモデルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# とりあえず初期化したモデルのembeddingを使って進める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "relation_size = len(set(list(dataset.triplet_df['relation'].values)))\n",
    "entity_size = len(dataset.entity_list)\n",
    "embed_model = TransE(int(embedding_dim), relation_size, entity_size).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_nodes_from([i for i in range(len(dataset.entity_list))])\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_matrix(G, item_mat=None, alpha=0.85, beta=0.01, personalization=None,\n",
    "                  weight='weight', dangling=None):\n",
    "\n",
    "    nodelist = G.nodes()\n",
    "\n",
    "    M = nx.to_numpy_matrix(G, nodelist=nodelist, weight=weight)\n",
    "    N = len(G)\n",
    "    if N == 0:\n",
    "        return M\n",
    "\n",
    "    # Personalization vector\n",
    "    if personalization is None:\n",
    "        p = np.repeat(1.0 / N, N)\n",
    "    else:\n",
    "        missing = set(nodelist) - set(personalization)\n",
    "        if missing:\n",
    "            raise NetworkXError('Personalization vector dictionary '\n",
    "                                'must have a value for every node. '\n",
    "                                'Missing nodes %s' % missing)\n",
    "        p = np.array([personalization[n] for n in nodelist], dtype=float)\n",
    "        p /= p.sum()\n",
    "\n",
    "    #print(p)\n",
    "    #print(p.shape)\n",
    "        \n",
    "    # Dangling nodes\n",
    "    if dangling is None:\n",
    "        dangling_weights = p\n",
    "    else:\n",
    "        missing = set(nodelist) - set(dangling)\n",
    "        if missing:\n",
    "            raise NetworkXError('Dangling node dictionary '\n",
    "                                'must have a value for every node. '\n",
    "                                'Missing nodes %s' % missing)\n",
    "        # Convert the dangling dictionary into an array in nodelist order\n",
    "        dangling_weights = np.array([dangling[n] for n in nodelist],\n",
    "                                    dtype=float)\n",
    "        dangling_weights /= dangling_weights.sum()\n",
    "    dangling_nodes = np.where(M.sum(axis=1) == 0)[0]\n",
    "\n",
    "    # Assign dangling_weights to any dangling nodes (nodes with no out links)\n",
    "    for node in dangling_nodes:\n",
    "        M[node] = dangling_weights\n",
    "\n",
    "    \n",
    "    M /= M.sum(axis=1)  # Normalize rows to sum to 1\n",
    "    \n",
    "    if item_mat is not None:\n",
    "        sim_mat = mk_sim_mat(G, item_mat)\n",
    "\n",
    "        M = beta * M + (1 - beta) * sim_mat\n",
    "    \n",
    "    return alpha * M + (1 - alpha) * p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_sim_mat(G, item_mat):\n",
    "    M = np.eye(len(G.nodes()))\n",
    "    #M = np.eye(4)\n",
    "    item_len = item_mat.shape[0]\n",
    "    M[0:item_len, 0:item_len] = item_mat\n",
    "    \n",
    "    # RecWalk論文の定義\n",
    "    M = M / np.max(M.sum(axis=1)) + np.diag(1 - M.sum(axis=1) / np.max(M.sum(axis=1)))\n",
    "   \n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sparse sim_matを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AmazonDataset('./data', model_name='TransE')\n",
    "\n",
    "def mk_sparse_sim_mat(model):\n",
    "    item_idx = torch.tensor([dataset.entity_list.index(i) for i in dataset.item_list], \n",
    "                        dtype=torch.long, device=device)\n",
    "\n",
    "    user_idx = torch.tensor([dataset.entity_list.index(u) for u in dataset.user_list], \n",
    "                        dtype=torch.long, device=device)\n",
    "\n",
    "    brand_idx = torch.tensor([dataset.entity_list.index(b) for b in dataset.brand_list], \n",
    "                        dtype=torch.long, device=device)\n",
    "    \n",
    "    # ここもっと上手く書きたい\n",
    "    item_embed = model.entity_embed(item_idx)\n",
    "    item_sim_mat = torch.mm(item_embed, torch.t(item_embed))\n",
    "    item_sim_mat = scipy.sparse.csr_matrix(item_sim_mat.to('cpu').detach().numpy().copy())\n",
    "\n",
    "    user_embed = model.entity_embed(user_idx)\n",
    "    user_sim_mat = torch.mm(user_embed, torch.t(user_embed))\n",
    "    user_sim_mat = scipy.sparse.csr_matrix(user_sim_mat.to('cpu').detach().numpy().copy())\n",
    "\n",
    "    brand_embed = model.entity_embed(brand_idx)\n",
    "    brand_sim_mat = torch.mm(brand_embed, torch.t(brand_embed))\n",
    "    brand_sim_mat = scipy.sparse.csr_matrix(brand_sim_mat.to('cpu').detach().numpy().copy())\n",
    "\n",
    "    M = scipy.sparse.block_diag((item_sim_mat, user_sim_mat, brand_sim_mat))\n",
    "    M_ = np.array(1 - M.sum(axis=1) / np.max(M.sum(axis=1)))\n",
    "                                    \n",
    "    M = M / np.max(M.sum(axis=1)) + scipy.sparse.diags(M_.transpose()[0])\n",
    "    #print(type(M))\n",
    "    #print(M.shape)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank_numpy(G, item_mat, alpha=0.85, beta=0.01, personalization=None, weight='weight',\n",
    "                   dangling=None):\n",
    "\n",
    "    import numpy as np\n",
    "    if len(G) == 0:\n",
    "        return {}\n",
    "    M = google_matrix(G, item_mat, alpha, beta, personalization=personalization,\n",
    "                      weight=weight, dangling=dangling)\n",
    "    #return 0\n",
    "    # use numpy LAPACK solver\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(M.T)\n",
    "    ind = eigenvalues.argsort()\n",
    "    # eigenvector of largest eigenvalue at ind[-1], normalized\n",
    "    largest = np.array(eigenvectors[:, ind[-1]]).flatten().real\n",
    "    norm = float(largest.sum())\n",
    "    return dict(zip(G, map(float, largest / norm)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank_scipy(G, model, alpha=0.85, beta=0.01, personalization=None,\n",
    "                   max_iter=700, tol=1.0e-6, weight='weight',\n",
    "                   dangling=None):\n",
    "    \n",
    "    import scipy.sparse\n",
    "\n",
    "    N = len(G)\n",
    "    if N == 0:\n",
    "        return {}\n",
    "\n",
    "    nodelist = G.nodes()\n",
    "    M = nx.to_scipy_sparse_matrix(G, nodelist=nodelist, weight=weight,\n",
    "                                  dtype=float)\n",
    "    S = scipy.array(M.sum(axis=1)).flatten()\n",
    "    S[S != 0] = 1.0 / S[S != 0]\n",
    "    Q = scipy.sparse.spdiags(S.T, 0, *M.shape, format='csr')\n",
    "    M = Q * M\n",
    "\n",
    "    # initial vector\n",
    "    x = scipy.repeat(1.0 / N, N)\n",
    "\n",
    "    # Personalization vector\n",
    "    if personalization is None:\n",
    "        p = scipy.repeat(1.0 / N, N)\n",
    "    else:\n",
    "        missing = set(nodelist) - set(personalization)\n",
    "        if missing:\n",
    "            raise NetworkXError('Personalization vector dictionary '\n",
    "                                'must have a value for every node. '\n",
    "                                'Missing nodes %s' % missing)\n",
    "        p = scipy.array([personalization[n] for n in nodelist],\n",
    "                        dtype=float)\n",
    "        p = p / p.sum()\n",
    "\n",
    "    # Dangling nodes\n",
    "    if dangling is None:\n",
    "        dangling_weights = p\n",
    "    else:\n",
    "        missing = set(nodelist) - set(dangling)\n",
    "        if missing:\n",
    "            raise NetworkXError('Dangling node dictionary '\n",
    "                                'must have a value for every node. '\n",
    "                                'Missing nodes %s' % missing)\n",
    "        # Convert the dangling dictionary into an array in nodelist order\n",
    "        dangling_weights = scipy.array([dangling[n] for n in nodelist],\n",
    "                                       dtype=float)\n",
    "        dangling_weights /= dangling_weights.sum()\n",
    "    is_dangling = scipy.where(S == 0)[0]\n",
    "\n",
    "    \n",
    "    # 遷移行列とsim_matを統合\n",
    "    sim_mat = mk_sparse_sim_mat(model)\n",
    "    M = beta * M + (1 - beta) * sim_mat\n",
    "\n",
    "    #return 0\n",
    "    \n",
    "    # power iteration: make up to max_iter iterations\n",
    "    x = torch.tensor(x, dtype=torch.float, device=device).view(len(x), -1)\n",
    "    M = torch.tensor(M, dtype=torch.float, device=device).to_sparse()\n",
    "    dangling_weights = torch.tensor(dangling_weights, device=device)\n",
    "    p = torch.tensor(p, device=device)\n",
    "    for _ in range(max_iter):\n",
    "        xlast = x\n",
    "        #x = alpha * (x * M + sum(x[is_dangling]) * dangling_weights) + \\\n",
    "        #    (1 - alpha) * p\n",
    "        x = alpha * (torch.sparse.mm(M, x) + sum(x[is_dangling]) * dangling_weights) + (1 - alpha) * p\n",
    "        x = x / x.sum()\n",
    "        # check convergence, l1 norm\n",
    "        #err = scipy.absolute(x - xlast).sum()\n",
    "        err = torch.abs(x - xlast)\n",
    "        if err < N * tol:\n",
    "            return dict(zip(nodelist, map(float, x)))\n",
    "    print(err)\n",
    "    print(N * tol)\n",
    "    #raise NetworkXError('pagerank_scipy: power iteration failed to converge '\n",
    "    #                    'in %d iterations.' % max_iter)\n",
    "    return dict(zip(nodelist, map(float, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3b5df82abca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpersonal_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpagerank_scipy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersonalization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpersonal_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_idx' is not defined"
     ]
    }
   ],
   "source": [
    "val = np.zeros(len(G.nodes()))\n",
    "val[user_idx[10]] = 1\n",
    "k = [i for i in range(len(G.nodes()))]\n",
    "personal_vec = dict(zip(k, val))\n",
    "pagerank_scipy(G, model, alpha = 0.9, beta=0.01, personalization=personal_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx = [dataset.entity_list.index(u) for u in dataset.user_list]\n",
    "\n",
    "def item_ppr(model, user, alpha, beta):\n",
    "    val = np.zeros(len(G.nodes()))\n",
    "    val[user] = 1\n",
    "    k = [i for i in range(len(G.nodes()))]\n",
    "    personal_vec = dict(zip(k, val))\n",
    "    #print(personal_vec)\n",
    "    ppr = pagerank_scipy(G, model, alpha, beta, personalization=personal_vec)\n",
    "    \n",
    "    # random 後で消す\n",
    "    # val = np.random.dirichlet([1 for i in range(len(G.nodes))], 1)[0]\n",
    "    #val = np.random.rand(len(G.nodes()))\n",
    "    #val /= val.sum()\n",
    "    #k = [i for i in range(len(G.nodes))]\n",
    "    #ppr = dict(zip(k, val))\n",
    "    \n",
    "    pred = []\n",
    "    item_idx = [dataset.entity_list.index(i) for i in dataset.item_list]\n",
    "    for i in item_idx:\n",
    "        pred.append(ppr[i])\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "def get_ranking_mat(model, alpha=0.85, beta=0.01):\n",
    "    ranking_mat = []\n",
    "    count = 0\n",
    "    for u in user_idx:\n",
    "        pred = item_ppr(model, u, alpha, beta)\n",
    "        #print(pred)\n",
    "        sorted_idx = np.argsort(np.array(pred))[::-1]\n",
    "        ranking_mat.append(sorted_idx)\n",
    "        \n",
    "        #count += 1\n",
    "        #if count > 100:\n",
    "        #    break\n",
    "            \n",
    "    return ranking_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx = [dataset.entity_list.index(u) for u in dataset.user_list]\n",
    "user_items_test_dict = pickle.load(open('./data/user_items_test_dict.pickle', 'rb'))\n",
    "\n",
    "def topn_precision(ranking_mat, user_items_dict, n=10):\n",
    "    not_count = 0\n",
    "    precision_sum = 0\n",
    "        \n",
    "    for i in range(len(ranking_mat)):\n",
    "        if len(user_items_dict[user_idx[i]]) == 0:\n",
    "            not_count += 1\n",
    "            continue\n",
    "        sorted_idx = ranking_mat[i]\n",
    "        topn_idx = sorted_idx[:n]  \n",
    "        hit = len(set(topn_idx) & set(user_items_dict[user_idx[i]]))\n",
    "        precision = hit / len(user_items_dict[user_idx[i]])\n",
    "        precision_sum += precision\n",
    "        \n",
    "    return precision_sum / (len(user_idx) - not_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    gamma = 1e-4\n",
    "    lin_model = 'lasso'\n",
    "    slim = train_SLIM(lin_model, gamma)\n",
    "    \n",
    "    alpha = 0.85\n",
    "    beta = 0.01\n",
    "    \n",
    "    ranking_mat = get_ranking_mat(slim, alpha, beta)\n",
    "    score = topn_precision(ranking_mat, user_items_test_dict)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2d76100c6de7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train embed model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-45b4ed38560d>\u001b[0m in \u001b[0;36mtrain_embed\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0miterater\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainIterater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     score =iterater.iterate_epoch(model, lr=lr, epoch=5000, weight_decay=weight_decay, warmup=warmup,\n\u001b[0;32m---> 17\u001b[0;31m                            lr_decay_rate=lr_decay_rate, lr_decay_every=lr_decay_every, eval_every=1e+5)\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/recsys_embed_ppr/PROPOSED/training.py\u001b[0m in \u001b[0;36miterate_epoch\u001b[0;34m(self, model, lr, epoch, weight_decay, warmup, lr_decay_rate, lr_decay_every, eval_every)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mplot_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e+5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# lrスケジューリング\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/recsys_embed_ppr/PROPOSED/training.py\u001b[0m in \u001b[0;36miterate_train\u001b[0;34m(self, model, lr, weight_decay, print_every, plot_every)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/recsys_embed_ppr/PROPOSED/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, batch, loss_func, optimizer, model)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'TransE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mposi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnega_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposi_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposi_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposi_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train embed model\n",
    "model = train_embed(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def time_since(runtime):\n",
    "    mi = int(runtime / 60)\n",
    "    sec = int(runtime - mi * 60)\n",
    "    return (mi, sec)\n",
    "\n",
    "def objective(trial):\n",
    "    start = time.time()\n",
    "    #gamma = trial.suggest_loguniform('gamma', 1e-6, 1e-3)\n",
    "    #lin_model = trial.suggest_categorical('lin_model', ['lasso', 'elastic'])\n",
    "    #slim = train_SLIM(lin_model, gamma)\n",
    "    model = embed_model\n",
    "    \n",
    "    alpha = trial.suggest_uniform('alpha', 0, 1)\n",
    "    beta = trial.suggest_uniform('beta', 0, 0.5)\n",
    "    \n",
    "    ranking_mat = get_ranking_mat(model, alpha, beta)\n",
    "    score = topn_precision(ranking_mat, user_items_test_dict)\n",
    "    mi, sec = time_since(time.time() - start)\n",
    "    print('{}m{}sec'.format(mi, sec))\n",
    "    \n",
    "    return -1 * score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0950097760045214\n",
      "0.0054069999999999995\n",
      "1.467835142617038\n",
      "0.0054069999999999995\n",
      "0.08118927580998431\n",
      "0.0054069999999999995\n",
      "0.196230822180708\n",
      "0.0054069999999999995\n",
      "0.13972353452635428\n",
      "0.0054069999999999995\n",
      "0.2502308984936981\n",
      "0.0054069999999999995\n",
      "1.0412971031257838\n",
      "0.0054069999999999995\n",
      "0.029344765692713944\n",
      "0.0054069999999999995\n",
      "0.660073442790822\n",
      "0.0054069999999999995\n",
      "0.06440584380511978\n",
      "0.0054069999999999995\n",
      "0.024165961202469364\n",
      "0.0054069999999999995\n",
      "0.22277733428075597\n",
      "0.0054069999999999995\n",
      "0.20014518710230234\n",
      "0.0054069999999999995\n",
      "0.2425041234966784\n",
      "0.0054069999999999995\n",
      "0.1781767488797314\n",
      "0.0054069999999999995\n",
      "1.0706281499837595\n",
      "0.0054069999999999995\n",
      "0.07304543981032\n",
      "0.0054069999999999995\n",
      "0.06895866535096921\n",
      "0.0054069999999999995\n",
      "0.013890415331514316\n",
      "0.0054069999999999995\n",
      "1.1364351913139736\n",
      "0.0054069999999999995\n",
      "3.7175041179274544\n",
      "0.0054069999999999995\n",
      "0.00909680638321488\n",
      "0.0054069999999999995\n",
      "3.85863452221742\n",
      "0.0054069999999999995\n",
      "0.1565057837676518\n",
      "0.0054069999999999995\n",
      "0.9295452485607303\n",
      "0.0054069999999999995\n",
      "0.3729976493037781\n",
      "0.0054069999999999995\n",
      "0.11332428612959602\n",
      "0.0054069999999999995\n",
      "0.3077872985300047\n",
      "0.0054069999999999995\n",
      "0.3598117193465777\n",
      "0.0054069999999999995\n",
      "0.4441355290348209\n",
      "0.0054069999999999995\n",
      "0.5184754715824922\n",
      "0.0054069999999999995\n",
      "0.6296312489525604\n",
      "0.0054069999999999995\n",
      "0.6530309401481815\n",
      "0.0054069999999999995\n",
      "0.013687063735312352\n",
      "0.0054069999999999995\n",
      "0.9877308292105457\n",
      "0.0054069999999999995\n",
      "0.3448210014191843\n",
      "0.0054069999999999995\n",
      "0.04024209845598216\n",
      "0.0054069999999999995\n",
      "0.4064513603679086\n",
      "0.0054069999999999995\n",
      "0.34009145435929283\n",
      "0.0054069999999999995\n",
      "1.6265444597428893\n",
      "0.0054069999999999995\n",
      "0.7460655093521354\n",
      "0.0054069999999999995\n",
      "0.5778547507300061\n",
      "0.0054069999999999995\n",
      "1.4823144405663182\n",
      "0.0054069999999999995\n",
      "0.006593402147213001\n",
      "0.0054069999999999995\n",
      "5.842789775275678\n",
      "0.0054069999999999995\n",
      "0.3053003312535716\n",
      "0.0054069999999999995\n",
      "0.5610301155273282\n",
      "0.0054069999999999995\n",
      "0.11122052138204715\n",
      "0.0054069999999999995\n",
      "0.21741745859672063\n",
      "0.0054069999999999995\n",
      "3.34679838303333\n",
      "0.0054069999999999995\n",
      "1.0830578199137366\n",
      "0.0054069999999999995\n",
      "0.37487954751883684\n",
      "0.0054069999999999995\n",
      "0.10190174123939594\n",
      "0.0054069999999999995\n",
      "0.4909993895615911\n",
      "0.0054069999999999995\n",
      "0.1372789609951501\n",
      "0.0054069999999999995\n",
      "0.24897602613590353\n",
      "0.0054069999999999995\n",
      "0.43000701663871466\n",
      "0.0054069999999999995\n",
      "0.5220919858321418\n",
      "0.0054069999999999995\n",
      "0.40528280217725365\n",
      "0.0054069999999999995\n",
      "0.14104513448622086\n",
      "0.0054069999999999995\n",
      "0.037888182215671605\n",
      "0.0054069999999999995\n",
      "0.7736415558192875\n",
      "0.0054069999999999995\n",
      "0.5497249321088118\n",
      "0.0054069999999999995\n",
      "0.03736886577691496\n",
      "0.0054069999999999995\n",
      "21.298468624148207\n",
      "0.0054069999999999995\n",
      "3.7919154874518997\n",
      "0.0054069999999999995\n",
      "0.33699999435125805\n",
      "0.0054069999999999995\n",
      "0.39674898576957773\n",
      "0.0054069999999999995\n",
      "1.1531886635350321\n",
      "0.0054069999999999995\n",
      "15.016930201934674\n",
      "0.0054069999999999995\n",
      "0.46144303456228103\n",
      "0.0054069999999999995\n",
      "0.18498689547291655\n",
      "0.0054069999999999995\n",
      "0.3149986745708597\n",
      "0.0054069999999999995\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-59dfbea0c2b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 self._optimize_sequential(\n\u001b[0;32m--> 339\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 )\n\u001b[1;32m    341\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    680\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             message = \"Setting status of trial#{} as {}. {}\".format(\n",
      "\u001b[0;32m<ipython-input-43-a9d0974de269>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'beta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mranking_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ranking_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopn_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranking_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_items_test_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_since\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-8f08e529c170>\u001b[0m in \u001b[0;36mget_ranking_mat\u001b[0;34m(model, alpha, beta)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muser_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_ppr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;31m#print(pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0msorted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-8f08e529c170>\u001b[0m in \u001b[0;36mitem_ppr\u001b[0;34m(model, user, alpha, beta)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpersonal_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print(personal_vec)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mppr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpagerank_scipy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersonalization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpersonal_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# random 後で消す\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-b5a97cd8ba7c>\u001b[0m in \u001b[0;36mpagerank_scipy\u001b[0;34m(G, model, alpha, beta, personalization, max_iter, tol, weight, dangling)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mxlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mis_dangling\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdangling_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__rmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m                 \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;31m#####################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;31m# Fast path for the most common case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_vector\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;31m# csr_matvec or csc_matvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_matvec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005572710458254794\n"
     ]
    }
   ],
   "source": [
    "df = study.trials_dataframe() # pandasのDataFrame形式\n",
    "df.to_csv('./hyparams_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best params \n",
    "with open('best_param.pickle', 'wb') as f:\n",
    "    pickle.dump(study.best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 2]], dtype=torch.float, device=device).to_sparse()\n",
    "print(a.shape)\n",
    "b = torch.tensor([2, 1], dtype=torch.float, device=device).view(2, -1)\n",
    "c = torch.sparse.mm(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.],\n",
       "        [8.]], device='cuda:0')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., device='cuda:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(b - c).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 4.0, 2: 8.0}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip([1, 2], map(float, c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
