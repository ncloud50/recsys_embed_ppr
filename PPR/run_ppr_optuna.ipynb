{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPRを動かしたい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ読み込み\n",
    "triplet_df = pd.read_csv('./data/triplet.csv')\n",
    "edges = [[r[0], r[1]] for r in triplet_df.values]\n",
    "\n",
    "entity_list = []\n",
    "user_list =[]\n",
    "item_list = []\n",
    "with open('./data/entity_list.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        entity_list.append(l.replace('\\n', ''))\n",
    "        \n",
    "with open('./data/user_list.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        user_list.append(l.replace('\\n', ''))\n",
    "        \n",
    "with open('./data/item_list.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        item_list.append(l.replace('\\n', ''))\n",
    "        \n",
    "        \n",
    "user_items_test_dict = pickle.load(open('./data/user_items_test_dict.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ページランク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges: 15899\n",
      "nodes: 5407\n"
     ]
    }
   ],
   "source": [
    "# グラフを作る\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from([i for i in range(len(entity_list))])\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# tripletに重複が存在する\n",
    "\n",
    "print('edges: {}'.format(len(G.edges)))\n",
    "print('nodes: {}'.format(len(G.nodes)))\n",
    "\n",
    "\n",
    "user_idx = [entity_list.index(u) for u in user_list]\n",
    "\n",
    "\n",
    "def item_ppr(user, alpha):\n",
    "    val = np.zeros(len(G.nodes))\n",
    "    val[user] = 1\n",
    "    k = [i for i in range(len(G.nodes))]\n",
    "    personal_vec = dict(zip(k, val))\n",
    "    #print(personal_vec)\n",
    "    ppr = nx.pagerank_scipy(G, alpha=alpha)\n",
    "    \n",
    "    # random 後で消す\n",
    "    #val = np.random.dirichlet([1 for i in range(len(G.nodes))], 1)[0]\n",
    "    #k = [i for i in range(len(G.nodes))]\n",
    "    #ppr = dict(zip(k, val))\n",
    "    \n",
    "    pred = []\n",
    "    item_idx = [entity_list.index(i) for i in item_list]\n",
    "    for i in item_idx:\n",
    "        pred.append(ppr[i])\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "def get_ranking_mat(alpha=0.85):\n",
    "    ranking_mat = []\n",
    "    count = 0\n",
    "    for u in user_idx:\n",
    "        pred = item_ppr(u, alpha)\n",
    "        #print(pred)\n",
    "        sorted_idx = np.argsort(np.array(pred))[::-1]\n",
    "        ranking_mat.append(sorted_idx)\n",
    "        \n",
    "        #count += 1\n",
    "        #if count > 100:\n",
    "        #    break\n",
    "            \n",
    "    return ranking_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx = [entity_list.index(u) for u in user_list]\n",
    "\n",
    "\n",
    "def topn_precision(ranking_mat, user_items_dict, n=10):\n",
    "    not_count = 0\n",
    "    precision_sum = 0\n",
    "        \n",
    "    for i in range(len(ranking_mat)):\n",
    "        if len(user_items_dict[user_idx[i]]) == 0:\n",
    "            not_count += 1\n",
    "            continue\n",
    "        sorted_idx = ranking_mat[i]\n",
    "        topn_idx = sorted_idx[:n]  \n",
    "        hit = len(set(topn_idx) & set(user_items_dict[user_idx[i]]))\n",
    "        precision = hit / len(user_items_dict[user_idx[i]])\n",
    "        precision_sum += precision\n",
    "        \n",
    "    return precision_sum / (len(user_idx) - not_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_since(runtime):\n",
    "    mi = int(runtime / 60)\n",
    "    sec = int(runtime - mi * 60)\n",
    "    return (mi, sec)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    start = time.time()\n",
    "    alpha = trial.suggest_uniform('alpha', 0, 1)\n",
    "    ranking_mat = get_ranking_mat(alpha)\n",
    "    score = topn_precision(ranking_mat, user_items_test_dict)\n",
    "    mi, sec = time_since(time.time() - start)\n",
    "    print('{}m{}s'.format(mi, sec))\n",
    "    return -1 * score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6m19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-07-03 19:10:39,563] Finished trial#0 with value: -0.14020407472100876 with parameters: {'alpha': 0.23707059694512522}. Best is trial#0 with value: -0.14020407472100876.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6m41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-07-03 19:17:20,689] Finished trial#1 with value: -0.018151265023270503 with parameters: {'alpha': 0.8501888823232407}. Best is trial#0 with value: -0.14020407472100876.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005537243893912877\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    ranking_mat = get_ranking_mat()\n",
    "    score = topn_precision(ranking_mat, user_items_test_dict)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータを保存しておく\n",
    "df = study.trials_dataframe() # pandasのDataFrame形式\n",
    "df.to_csv('hyparams_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}