{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python APIs for the SLIM package\n",
    "\n",
    "## Installation\n",
    "Before installing the python APIs for the SLIM package, please make sure that the slim library is built correctly. To install the python APIs, please follow one of the following steps,\n",
    "\n",
    "1. Install python-package system-wide, this requires root permission:\n",
    "> sudo python setup.py install\n",
    "\n",
    "2. Install python-package only for the current users (without sudo priveleges)\n",
    "> python setup.py install --user\n",
    "\n",
    "## Data Interface\n",
    "The SLIM package is able to load\n",
    "1. ijv triplets data in the form of {userid, itemid, rating} from:\n",
    "    - Pandas DataFrame (pandas.DataFrame)\n",
    "    - NumPy 2d arrays (numpy.array)\n",
    "    - list(list) (list[list[i, j, v]])\n",
    "2. csr matrix from:\n",
    "    - SciPy 2D sparse csr matrix (scipy.sparse.csr.csr_matrix)\n",
    "\n",
    "The data is stored in a SLIMatrix object. The SLIM package **ONLY** accepts SLIMatrix objects as training and validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ijv triplets from pandas DataFrames\n",
    "import pandas as pd\n",
    "from SLIM import SLIMatrix\n",
    "\n",
    "traindata = pd.read_csv('../test/AutomotiveTrain.ijv', \n",
    "                        delimiter=' ', \n",
    "                        header=None, \n",
    "                        names=['userid', 'itemid', 'rating'])\n",
    "trainmat = SLIMatrix(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ijv triplets from numpy 2d arrays\n",
    "import numpy as np\n",
    "from SLIM import SLIMatrix\n",
    "\n",
    "traindata = np.genfromtxt('../test/AutomotiveTrain.ijv', delimiter=' ')\n",
    "trainmat = SLIMatrix(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ijv triplets from list[list]\n",
    "def load_data(fname, delimiter=' ', header=False):\n",
    "    data = []\n",
    "    f = open(fname)\n",
    "\n",
    "    if header:\n",
    "        line = f.readline()\n",
    "        \n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            triplet = line.split(delimiter)\n",
    "            data.append([triplet[0], triplet[1], float(triplet[2])])\n",
    "    else:\n",
    "        for line in f:\n",
    "            triplet = line.split(delimiter)\n",
    "            data.append([triplet[0], triplet[1], float(triplet[2])])\n",
    "    \n",
    "    return data\n",
    "\n",
    "from SLIM import SLIMatrix\n",
    "\n",
    "traindata = load_data('../test/AutomotiveTrain.ijv', delimiter=' ', header=False)\n",
    "trainmat = SLIMatrix(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csr matrix from scipy 2d sparse csr matrices\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from SLIM import SLIMatrix\n",
    "\n",
    "traindata = pd.read_csv('../test/AutomotiveTrain.ijv', \n",
    "                        delimiter=' ', \n",
    "                        header=None, \n",
    "                        names=['userid', 'itemid', 'rating'],\n",
    "                        dtype={'userid':np.int32, 'itemid':np.int32, 'rating':np.float32})\n",
    "\n",
    "# get the map of users and the map of items\n",
    "id2user, row = np.unique(traindata['userid'], return_inverse=True)\n",
    "id2item, col = np.unique(traindata['itemid'], return_inverse=True)\n",
    "dat = traindata['rating'].values\n",
    "num_users = len(id2user)\n",
    "num_items = len(id2item)\n",
    "\n",
    "# create a scipy csr matrix\n",
    "csr_matrix = scipy.sparse.csr_matrix((dat, (row, col)), shape=(num_users, num_items))\n",
    "\n",
    "trainmat = SLIMatrix(csr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Setting\n",
    "SLIM package supports setting parameters using a dictionary or from command line using argparse. For a detail description of the parameters allowed, please refer to the README. For an example of using argparse to pass parameters from command line, please refer to the main.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters using dictionary\n",
    "params = {'dbglvl':0, 'nnbrs':0, 'algo':'cd', 'nthreads':1, 'l1r':1., 'l2r':1.}\n",
    "\n",
    "params['optTol'] = 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "Training a model requires a set of parameters and a training rating matrix as a SLIMatrix object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning takes 0.245 secs.\n"
     ]
    }
   ],
   "source": [
    "# training a SLIM model\n",
    "import pandas as pd\n",
    "from SLIM import SLIM, SLIMatrix\n",
    "\n",
    "traindata = pd.read_csv('../test/AutomotiveTrain.ijv', delimiter=' ', header=None)\n",
    "trainmat = SLIMatrix(traindata)\n",
    "\n",
    "params = {'dbglvl':0, \n",
    "          'algo':'cd', \n",
    "          'nthreads':1, \n",
    "          'l1r':1., \n",
    "          'l2r':1.,\n",
    "          'optTol':1e-7,\n",
    "          'niters':100}\n",
    "\n",
    "model = SLIM()\n",
    "model.train(params, trainmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, the model can be saved and loaded. Note that, in order for the model to be used in the future, a map that project the item ids to integers are required to be stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load a SLIM model\n",
    "model.save_model(modelfname='model.csr', # filename to save the model as a csr matrix\n",
    "                 mapfname='map.csr' # filename to save the item map\n",
    "                )\n",
    "\n",
    "model_new = SLIM()\n",
    "model_new.load_model(modelfname='model.csr', # filename of the model\n",
    "                 mapfname='map.csr' # filename of the item map\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with an Existing Model\n",
    "In order to predict using a learned model, the item ids of the input matrix are required to be consistent with that of the model. If the matrix to be predicted is the training matrix,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using the training matrix\n",
    "output = model.predict(trainmat, nrcmds=10, outfile='output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the matrix to be predicted is a new matrix with the same set of items, please initialize the input matrix using the model,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = SLIM()\n",
    "model_new.load_model(modelfname='model.csr', # filename of the model\n",
    "                 mapfname='map.csr' # filename of the item map\n",
    "                )\n",
    "\n",
    "inputdata = pd.read_csv('../test/AutomotiveTest.ijv', delimiter=' ', header=None)\n",
    "# initialize the input matrix using the item model\n",
    "inputmat = SLIMatrix(inputdata, \n",
    "                     oldmat=model_new)\n",
    "output = model_new.predict(inputmat, nrcmds=10, outfile='output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the predict function is a dictionary in which the keys are the user ids and the values are the top-$n$ recommendation lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "We provide an useful tool for efficient model selection across a set of l1 and l2 pairs. The model selection procedure requires a set of parameters, a training matrix, a validation matrix, a list of l1 values, a list of l2 values and the length of the recommendation list. Note that, in order for the function to train the models on the training matrix and evaluate the performance on the validation matrix, the user ids and the item ids of the training matrix and the validation matrix are required to be consistent. To achive this goal, please initialize the validation matrix using the training matrix. Currently, we only support model selection using Hit Rate and Average Reciprocal Hit Rank (ARHR). NDCG, Precision, and Recall will be added soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model selection takes 18.898 secs.\n",
      "The best HR is achieved by, l1: 20.0000, l2:0.1000, HR:0.1404, AR:0.0654.\n",
      "The best AR is achieved by, l1: 20.0000, l2:50.0000, HR:0.1390, AR:0.0669.\n"
     ]
    }
   ],
   "source": [
    "# model selection for SLIM models\n",
    "import pandas as pd\n",
    "from SLIM import SLIM, SLIMatrix\n",
    "\n",
    "traindata = pd.read_csv('../test/AutomotiveTrain.ijv', delimiter=' ', header=None)\n",
    "valdata = pd.read_csv('../test/AutomotiveTest.ijv', delimiter=' ', header=None)\n",
    "trainmat = SLIMatrix(traindata)\n",
    "# initlaize the validation matrix using the training matrix\n",
    "valmat = SLIMatrix(valdata, trainmat)\n",
    "\n",
    "params = {'dbglvl':3, \n",
    "          'algo':'cd', \n",
    "          'nthreads':1, \n",
    "          'l1r':1., \n",
    "          'l2r':1.,\n",
    "          'optTol':1e-7,\n",
    "          'niters':100}\n",
    "\n",
    "l1s = [0.01, 0.1, 0.5, 1, 2, 4, 5, 10, 20]\n",
    "l2s = [0.1, 0.5, 1, 2, 5, 10, 20, 30, 50]\n",
    "\n",
    "model = SLIM()\n",
    "model.mselect(params, trainmat, valmat, l1s, l2s, nrcmds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLIM with Feature Selection\n",
    "For training a SLIM model, the training algorithm needs to solve $n$ linear regression problems. SLIM with feature selection (fSLIM) reduces the number of independent variables using pre-defined heuristics for each of the linear regression problems. As a result, fSLIM achieves substantially higher training efficiency than SLIM with a modest compromise in recommendation accuracy.\n",
    "\n",
    "We implement fSLIM in this package. To train a fSLIM model, besides the parameters for SLIM models, two more parameters *nnbrs* and *simtype* are required. The parameter *nnbrs* is the one critical parameter that distinguishes training a SLIM model from training a fSLIM model. When *nnbrs* is set to a positive integer, a fSLIM will be trained. A SLIM model will be trained when *nnbrs* is set to 0 or left blank. The parameter *simtype* sets the measurement of similarity. This package supports three similarity measurements, Jaccard similarity (\"jac\"), Cosine similarity (\"cos\"), and inner product (\"dotp\"). The default value for *simtype* is \"cos\". A fSLIM model can be used in the same way with a SLIM model. Note that, a fSLIM model can only be trained using coordinate descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning takes 0.147 secs.\n"
     ]
    }
   ],
   "source": [
    "# training a fSLIM model\n",
    "import pandas as pd\n",
    "from SLIM import SLIM, SLIMatrix\n",
    "\n",
    "traindata = pd.read_csv('../test/AutomotiveTrain.ijv', delimiter=' ', header=None)\n",
    "trainmat = SLIMatrix(traindata)\n",
    "\n",
    "params = {'dbglvl':0, \n",
    "          'algo':'cd', \n",
    "          'nthreads':1, \n",
    "          'l1r':1., \n",
    "          'l2r':1.,\n",
    "          'optTol':1e-7,\n",
    "          'niters':100}\n",
    "\n",
    "# set the fSLIM specific parameters\n",
    "params['nnbrs'] = 10\n",
    "params['simtype'] = \"cos\"\n",
    "\n",
    "# other options for simtype\n",
    "# params['simtype'] = \"jac\"\n",
    "# params['simtype'] = \"dotp\"\n",
    "\n",
    "# a fSLIM model will be trained\n",
    "model = SLIM()\n",
    "model.train(params, trainmat)\n",
    "\n",
    "# use the trained fSLIM model to recommend\n",
    "output = model.predict(trainmat, nrcmds=10, outfile='output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
